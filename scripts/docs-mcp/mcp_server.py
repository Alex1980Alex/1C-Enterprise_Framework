#!/usr/bin/env python3
"""
MCP —Å–µ—Ä–≤–µ—Ä –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ 1C
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Claude Code —á–µ—Ä–µ–∑ Model Context Protocol
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.append(str(Path(__file__).parent))

try:
    from mcp.server import Server
    from mcp.types import Resource, Tool, TextContent, ImageContent, EmbeddedResource
    from hybrid_search_engine import HybridSearchEngine, SearchResult
    MCP_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False
    print("[ERROR] MCP –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install mcp")

class FrameworkDocsMCPServer:
    """MCP —Å–µ—Ä–≤–µ—Ä –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–µ—Ä–∞"""
        self.search_engine = HybridSearchEngine()
        self.server = Server("1c-framework-docs") if MCP_AVAILABLE else None
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å
        docs_root = os.getenv('DOCS_ROOT')
        if docs_root:
            self.docs_path = Path(docs_root)
        else:
            # –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            self.docs_path = Path("D:/1C-Enterprise_Framework/–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫—É")
        
        if MCP_AVAILABLE:
            self._setup_handlers()
    
    def _setup_handlers(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ MCP"""
        if not self.server:
            return
        
        # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        @self.server.list_tools()
        async def list_tools() -> List[Tool]:
            """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
            return [
                Tool(
                    name="search_docs",
                    description="–ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ 1C. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π, —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∏ –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫.",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ"
                            },
                            "limit": {
                                "type": "integer",
                                "description": "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)",
                                "default": 5,
                                "minimum": 1,
                                "maximum": 20
                            },
                            "search_type": {
                                "type": "string",
                                "description": "–¢–∏–ø –ø–æ–∏—Å–∫–∞: fulltext, semantic, hybrid",
                                "enum": ["fulltext", "semantic", "hybrid"],
                                "default": "hybrid"
                            }
                        },
                        "required": ["query"]
                    }
                ),
                Tool(
                    name="get_document",
                    description="–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ ID",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "document_id": {
                                "type": "string",
                                "description": "ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è"
                            }
                        },
                        "required": ["document_id"]
                    }
                ),
                Tool(
                    name="reindex_docs",
                    description="–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—Å–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "force": {
                                "type": "boolean",
                                "description": "–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
                                "default": False
                            }
                        }
                    }
                ),
                Tool(
                    name="get_stats",
                    description="–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞",
                    inputSchema={
                        "type": "object",
                        "properties": {}
                    }
                )
            ]
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        @self.server.call_tool()
        async def call_tool(name: str, arguments: Dict[str, Any]) -> List[TextContent]:
            """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
            
            if name == "search_docs":
                return await self._handle_search(arguments)
            elif name == "get_document":
                return await self._handle_get_document(arguments)
            elif name == "reindex_docs":
                return await self._handle_reindex(arguments)
            elif name == "get_stats":
                return await self._handle_get_stats(arguments)
            else:
                return [TextContent(
                    type="text",
                    text=f"[ERROR] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {name}"
                )]
    
    async def _handle_search(self, args: Dict[str, Any]) -> List[TextContent]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        query = args.get("query", "")
        limit = args.get("limit", 5)
        search_type = args.get("search_type", "hybrid")
        
        if not query.strip():
            return [TextContent(
                type="text",
                text="[ERROR] –ü—É—Å—Ç–æ–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"
            )]
        
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            results = self.search_engine.search(query, limit=limit, search_type=search_type)
            
            if not results:
                return [TextContent(
                    type="text",
                    text=f"[SEARCH] –ü–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
                )]
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            response_text = f"[SEARCH] **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É:** '{query}'\n"
            response_text += f"[STATS] **–¢–∏–ø –ø–æ–∏—Å–∫–∞:** {search_type}\n"
            response_text += f"[LIST] **–ù–∞–π–¥–µ–Ω–æ:** {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç(–æ–≤)\n\n"
            
            for i, result in enumerate(results, 1):
                doc = result.document
                score = result.score
                match_type = result.match_type
                snippet = result.snippet
                
                response_text += f"## {i}. {doc.title}\n"
                response_text += f"**[FOLDER] –§–∞–π–ª:** `{Path(doc.path).name}`\n"
                response_text += f"**[TARGET] –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å:** {score:.3f} ({match_type})\n"
                response_text += f"**üìè –†–∞–∑–º–µ—Ä:** {doc.size} —Å–∏–º–≤–æ–ª–æ–≤\n"
                response_text += f"**üè∑Ô∏è –¢–µ–≥–∏:** {', '.join(doc.tags) if doc.tags else '–Ω–µ—Ç'}\n"
                response_text += f"**[NOTE] –§—Ä–∞–≥–º–µ–Ω—Ç:**\n```\n{snippet}\n```\n"
                response_text += f"**üÜî ID:** `{doc.id}`\n\n"
                response_text += "---\n\n"
            
            response_text += f"[INFO] **–°–æ–≤–µ—Ç:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `get_document` —Å ID –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ.\n"
            
            return [TextContent(type="text", text=response_text)]
            
        except Exception as e:
            return [TextContent(
                type="text",
                text=f"[ERROR] –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}"
            )]
    
    async def _handle_get_document(self, args: Dict[str, Any]) -> List[TextContent]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        document_id = args.get("document_id", "")
        
        if not document_id:
            return [TextContent(
                type="text",
                text="[ERROR] –ù–µ —É–∫–∞–∑–∞–Ω ID –¥–æ–∫—É–º–µ–Ω—Ç–∞"
            )]
        
        try:
            # –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ ID
            import sqlite3
            conn = sqlite3.connect(self.search_engine.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT title, path, content, size, modified, tags, doc_type
                FROM documents 
                WHERE id = ?
            """, (document_id,))
            
            result = cursor.fetchone()
            conn.close()
            
            if not result:
                return [TextContent(
                    type="text",
                    text=f"[ERROR] –î–æ–∫—É–º–µ–Ω—Ç —Å ID '{document_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω"
                )]
            
            title, path, content, size, modified, tags, doc_type = result
            tags_list = json.loads(tags) if tags else []
            
            response_text = f"# [FILE] {title}\n\n"
            response_text += f"**[FOLDER] –ü—É—Ç—å:** `{path}`\n"
            response_text += f"**üìè –†–∞–∑–º–µ—Ä:** {size} —Å–∏–º–≤–æ–ª–æ–≤\n"
            response_text += f"**üìÖ –ò–∑–º–µ–Ω–µ–Ω:** {modified}\n"
            response_text += f"**üè∑Ô∏è –¢–µ–≥–∏:** {', '.join(tags_list) if tags_list else '–Ω–µ—Ç'}\n"
            response_text += f"**[LIST] –¢–∏–ø:** {doc_type}\n\n"
            response_text += "---\n\n"
            response_text += "## üìñ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ\n\n"
            response_text += content
            
            return [TextContent(type="text", text=response_text)]
            
        except Exception as e:
            return [TextContent(
                type="text",
                text=f"[ERROR] –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {str(e)}"
            )]
    
    async def _handle_reindex(self, args: Dict[str, Any]) -> List[TextContent]:
        """–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        force = args.get("force", False)
        
        try:
            if not self.docs_path.exists():
                return [TextContent(
                    type="text",
                    text=f"[ERROR] –ü–∞–ø–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.docs_path}"
                )]
            
            response_text = "[SYNC] **–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞**\n\n"
            
            indexed_count = 0
            skipped_count = 0
            error_count = 0
            
            # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤—Å–µ markdown —Ñ–∞–π–ª—ã
            for md_file in self.docs_path.rglob("*.md"):
                try:
                    if self.search_engine.index_document(str(md_file)):
                        indexed_count += 1
                        response_text += f"[OK] {md_file.name}\n"
                    else:
                        skipped_count += 1
                        response_text += f"‚è≠Ô∏è {md_file.name} (–∞–∫—Ç—É–∞–ª–µ–Ω)\n"
                except Exception as e:
                    error_count += 1
                    response_text += f"[ERROR] {md_file.name}: {e}\n"
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            response_text += f"\n[STATS] **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏:**\n"
            response_text += f"- [OK] –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {indexed_count}\n"
            response_text += f"- ‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}\n"
            response_text += f"- [ERROR] –û—à–∏–±–æ–∫: {error_count}\n"
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞
            stats = self.search_engine.get_statistics()
            response_text += f"\nüìà **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞:**\n"
            response_text += f"- [DOCS] –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats['total_documents']}\n"
            response_text += f"- üß† –° —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏: {stats['documents_with_embeddings']}\n"
            response_text += f"- [SAVE] –†–∞–∑–º–µ—Ä: {stats['total_size_mb']} MB\n"
            
            return [TextContent(type="text", text=response_text)]
            
        except Exception as e:
            return [TextContent(
                type="text",
                text=f"[ERROR] –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {str(e)}"
            )]
    
    async def _handle_get_stats(self, args: Dict[str, Any]) -> List[TextContent]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–Ω–¥–µ–∫—Å–∞"""
        try:
            stats = self.search_engine.get_statistics()
            
            response_text = "[STATS] **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞**\n\n"
            response_text += f"[DOCS] **–î–æ–∫—É–º–µ–Ω—Ç—ã:**\n"
            response_text += f"- –í—Å–µ–≥–æ: {stats['total_documents']}\n"
            response_text += f"- –° —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏: {stats['documents_with_embeddings']}\n"
            response_text += f"- –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–≥–æ–≤: {stats['unique_tags']}\n\n"
            
            response_text += f"[SAVE] **–†–∞–∑–º–µ—Ä:**\n"
            response_text += f"- –û–±—â–∏–π: {stats['total_size_mb']} MB\n"
            response_text += f"- –ë–∞–π—Ç: {stats['total_size_bytes']:,}\n\n"
            
            response_text += f"[LIST] **–¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:**\n"
            for doc_type, count in stats['document_types'].items():
                response_text += f"- {doc_type}: {count}\n"
            
            response_text += f"\nüß† **–≠–º–±–µ–¥–¥–∏–Ω–≥–∏:**\n"
            response_text += f"- –í–∫–ª—é—á–µ–Ω—ã: {'[OK]' if stats['embeddings_enabled'] else '[ERROR]'}\n"
            if stats['model_name']:
                response_text += f"- –ú–æ–¥–µ–ª—å: {stats['model_name']}\n"
            
            response_text += f"\n[CONFIG] **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n"
            response_text += f"- –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫: [OK] (SQLite FTS5)\n"
            response_text += f"- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫: {'[OK]' if stats['embeddings_enabled'] else '[ERROR]'}\n"
            response_text += f"- –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫: {'[OK]' if stats['embeddings_enabled'] else '[WARNING] (—Ç–æ–ª—å–∫–æ FTS5)'}\n"
            
            return [TextContent(type="text", text=response_text)]
            
        except Exception as e:
            return [TextContent(
                type="text",
                text=f"[ERROR] –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}"
            )]
    
    async def run(self):
        """–ó–∞–ø—É—Å–∫ MCP —Å–µ—Ä–≤–µ—Ä–∞"""
        if not MCP_AVAILABLE:
            print("[ERROR] MCP –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.")
            return
        
        print("[START] –ó–∞–ø—É—Å–∫ MCP —Å–µ—Ä–≤–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ 1C")
        print("[DOCS] –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:")
        print("  - search_docs: –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
        print("  - get_document: –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
        print("  - reindex_docs: –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è")
        print("  - get_stats: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞")
        print("\n[OK] –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        if self.docs_path.exists():
            print("[SYNC] –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")
            stats = self.search_engine.get_statistics()
            if stats['total_documents'] == 0:
                print("[DOCS] –ü–µ—Ä–≤–∏—á–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")
                for md_file in self.docs_path.rglob("*.md"):
                    self.search_engine.index_document(str(md_file))
                print("[OK] –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
        # –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
        from mcp.server.stdio import stdio_server
        async with stdio_server() as (read_stream, write_stream):
            await self.server.run(read_stream, write_stream, 
                                 self.server.create_initialization_options())


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    server = FrameworkDocsMCPServer()
    await server.run()


if __name__ == "__main__":
    if not MCP_AVAILABLE:
        print("[ERROR] –î–ª—è —Ä–∞–±–æ—Ç—ã —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ MCP:")
        print("pip install mcp sentence-transformers")
        sys.exit(1)
    
    asyncio.run(main())