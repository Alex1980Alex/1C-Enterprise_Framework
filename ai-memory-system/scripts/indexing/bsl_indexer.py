"""
BSL Indexer - –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è BSL —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
–°–∫–∞–Ω–∏—Ä—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –ø–∞—Ä—Å–∏—Ç –∫–æ–¥, —Å–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
"""

import os
import sys
import json
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
from dataclasses import dataclass, asdict

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—É—Ç–µ–π –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from services.embedding_service import EmbeddingService
from utils.bsl_parser import BSLParser, BSLModule

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class IndexedFile:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    file_path: str
    module_type: str
    functions_count: int
    variables_count: int
    searchable_text: str
    embedding: List[float]
    indexed_at: str
    file_size: int


class BSLIndexer:
    """
    –ò–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä BSL —Ñ–∞–π–ª–æ–≤
    """

    def __init__(
        self,
        output_dir: str = "D:/1C-Enterprise_Framework/ai-memory-system/data/index",
        embedding_model: str = "nomic-embed-text:latest"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞

        Args:
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞
            embedding_model: –ú–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.embedding_service = EmbeddingService(model=embedding_model)
        self.parser = BSLParser()

        self.indexed_files: List[IndexedFile] = []

        logger.info(f"BSLIndexer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –í—ã—Ö–æ–¥: {output_dir}")

    def index_directory(
        self,
        directory: str,
        max_files: Optional[int] = None,
        file_pattern: str = "*.bsl"
    ) -> int:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å BSL —Ñ–∞–π–ª–∞–º–∏

        Args:
            directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            max_files: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ (None = –≤—Å–µ)
            file_pattern: –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        logger.info(f"–ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {directory}")

        # –ü–æ–∏—Å–∫ BSL —Ñ–∞–π–ª–æ–≤
        dir_path = Path(directory)
        if not dir_path.exists():
            logger.error(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {directory}")
            return 0

        bsl_files = list(dir_path.rglob(file_pattern))
        total_files = len(bsl_files)

        if max_files:
            bsl_files = bsl_files[:max_files]
            logger.info(f"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: {max_files} —Ñ–∞–π–ª–æ–≤ –∏–∑ {total_files}")
        else:
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {total_files}")

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤
        success_count = 0
        for i, file_path in enumerate(bsl_files, 1):
            logger.info(f"[{i}/{len(bsl_files)}] {file_path.name}")

            if self._index_file(str(file_path)):
                success_count += 1

            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Ñ–∞–π–ª–æ–≤
            if i % 10 == 0:
                logger.info(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {i}/{len(bsl_files)} ({i*100//len(bsl_files)}%)")

        logger.info(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ. –£—Å–ø–µ—à–Ω–æ: {success_count}/{len(bsl_files)}")
        return success_count

    def _index_file(self, file_path: str) -> bool:
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            # –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞
            module = self.parser.parse_file(file_path)
            if not module:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å: {file_path}")
                return False

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            searchable_text = self.parser.extract_searchable_text(module)

            # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            embedding = self.embedding_service.create_embedding(searchable_text)
            if not embedding:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥: {file_path}")
                return False

            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
            file_size = Path(file_path).stat().st_size

            # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∏–Ω–¥–µ–∫—Å–∞
            indexed_file = IndexedFile(
                file_path=file_path,
                module_type=module.module_type,
                functions_count=len(module.functions),
                variables_count=len(module.variables),
                searchable_text=searchable_text,
                embedding=embedding,
                indexed_at=datetime.now().isoformat(),
                file_size=file_size
            )

            self.indexed_files.append(indexed_file)
            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {file_path}: {e}")
            return False

    def save_index(self, filename: str = "bsl_index.json"):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –≤ —Ñ–∞–π–ª

        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        output_path = self.output_dir / filename

        try:
            index_data = {
                "metadata": {
                    "created_at": datetime.now().isoformat(),
                    "total_files": len(self.indexed_files),
                    "embedding_model": self.embedding_service.model,
                    "embedding_dimension": len(self.indexed_files[0].embedding) if self.indexed_files else 0
                },
                "files": [asdict(f) for f in self.indexed_files]
            }

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, ensure_ascii=False, indent=2)

            logger.info(f"–ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            logger.info(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {output_path.stat().st_size / 1024 / 1024:.2f} MB")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞: {e}")

    def load_index(self, filename: str = "bsl_index.json") -> bool:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ —Ñ–∞–π–ª–∞

        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –∏–Ω–¥–µ–∫—Å–∞

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        input_path = self.output_dir / filename

        try:
            with open(input_path, 'r', encoding='utf-8') as f:
                index_data = json.load(f)

            self.indexed_files = [
                IndexedFile(**file_data)
                for file_data in index_data["files"]
            ]

            logger.info(f"–ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω: {input_path}")
            logger.info(f"–§–∞–π–ª–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ: {len(self.indexed_files)}")
            return True

        except FileNotFoundError:
            logger.warning(f"–§–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
            return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω–¥–µ–∫—Å–∞: {e}")
            return False

    def get_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        if not self.indexed_files:
            return {"total_files": 0}

        total_functions = sum(f.functions_count for f in self.indexed_files)
        total_variables = sum(f.variables_count for f in self.indexed_files)
        total_size = sum(f.file_size for f in self.indexed_files)

        module_types = {}
        for f in self.indexed_files:
            module_types[f.module_type] = module_types.get(f.module_type, 0) + 1

        return {
            "total_files": len(self.indexed_files),
            "total_functions": total_functions,
            "total_variables": total_variables,
            "total_size_mb": total_size / 1024 / 1024,
            "module_types": module_types,
            "embedding_model": self.embedding_service.model,
            "embedding_dimension": len(self.indexed_files[0].embedding)
        }

    def search_similar(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É

        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ñ–∞–π–ª–æ–≤ —Å –æ—Ü–µ–Ω–∫–∞–º–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        """
        if not self.indexed_files:
            logger.warning("–ò–Ω–¥–µ–∫—Å –ø—É—Å—Ç")
            return []

        # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self.embedding_service.create_embedding(query)
        if not query_embedding:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞")
            return []

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
        import numpy as np

        query_vec = np.array(query_embedding)
        similarities = []

        for indexed_file in self.indexed_files:
            file_vec = np.array(indexed_file.embedding)

            # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            similarity = np.dot(query_vec, file_vec) / (
                np.linalg.norm(query_vec) * np.linalg.norm(file_vec)
            )

            similarities.append({
                "file_path": indexed_file.file_path,
                "module_type": indexed_file.module_type,
                "similarity": float(similarity),
                "searchable_text": indexed_file.searchable_text[:200] + "..."
            })

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        similarities.sort(key=lambda x: x["similarity"], reverse=True)

        return similarities[:top_k]


# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    import argparse

    parser = argparse.ArgumentParser(description="BSL Indexer - –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è BSL —Ñ–∞–π–ª–æ–≤")
    parser.add_argument(
        "directory",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å BSL —Ñ–∞–π–ª–∞–º–∏"
    )
    parser.add_argument(
        "--max-files",
        type=int,
        default=100,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ (default: 100)"
    )
    parser.add_argument(
        "--output",
        default="D:/1C-Enterprise_Framework/ai-memory-system/data/index",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞"
    )
    parser.add_argument(
        "--search",
        help="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
    )

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞
    indexer = BSLIndexer(output_dir=args.output)

    # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è
    success_count = indexer.index_directory(
        args.directory,
        max_files=args.max_files
    )

    if success_count > 0:
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
        indexer.save_index()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = indexer.get_statistics()
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏:")
        print(f"   –§–∞–π–ª–æ–≤: {stats['total_files']}")
        print(f"   –§—É–Ω–∫—Ü–∏–π: {stats['total_functions']}")
        print(f"   –ü–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {stats['total_variables']}")
        print(f"   –†–∞–∑–º–µ—Ä: {stats['total_size_mb']:.2f} MB")
        print(f"   –ú–æ–¥–µ–ª—å: {stats['embedding_model']}")
        print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {stats['embedding_dimension']}")

        # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
        if args.search:
            print(f"\nüîç –ü–æ–∏—Å–∫: '{args.search}'")
            results = indexer.search_similar(args.search, top_k=3)

            for i, result in enumerate(results, 1):
                print(f"\n{i}. {Path(result['file_path']).name}")
                print(f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result['similarity']:.3f}")
                print(f"   –¢–∏–ø: {result['module_type']}")
                print(f"   –§—Ä–∞–≥–º–µ–Ω—Ç: {result['searchable_text'][:100]}...")


if __name__ == "__main__":
    main()
